'''
偏导数、梯度和链式法则
'''

'''
偏导数：对于一个多元函数y=f(x1,x2,x3...xN)，偏导数表示函数关于其中一个自变量的变化率，而保持其他自变量固定。
在神经网络中，损失函数L通常是关于多个权重w和偏置b的多元函数。计算偏导数可以确定每个参数对损失函数的影响程度。这有助于确定在优化过程中每个参数应该如何调整
'''

'''
梯度：梯度是一个向量，它包含了函数关于所有自变量的偏导数。
在神经网络中，以损失函数L为研究对象，计算其梯度（实际上就是损失函数的导数）。梯度方向指向函数值增长最快的方向，
而梯度的反方向则是损失函数下降最快的方向。在优化算法（如梯度下降）中，沿着梯度的反方向更新网络的权重和偏置，可以有效降低损失函数的值
'''

'''
链式法则：对于复合函数（无论是多复杂的复合函数），根据链式法则，对其求导或者对其任一中间变量求导，得到的结果在形式上是统一的。
在神经网络中，前向传播过程中，每一层的输出都是下一层的输入，本质也是一个复合函数。
当计算损失函数关于网络中某一层的权重或偏置的导数时，需要通过链式法则。
例如，从输出层到隐藏层再到输入层反向传播计算导数时，某一层的权重对损失函数的影响是通过后续层的一系列计算传递过来的。
链式法则是实现反向传播算法的关键数学原理，通过它可以高效计算出每个参数的偏导数，从而为基于梯度的优化算法提供必要的信息
'''